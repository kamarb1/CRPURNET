def resnest_block1(inputs, in_channels, out_channels, stride=1, groups=1):
    conv1 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=stride, padding='same', groups=groups, use_bias=False)(inputs)
    bn1 = tf.keras.layers.BatchNormalization()(conv1)
    relu = tf.keras.layers.ReLU()(bn1)
    conv2 = tf.keras.layers.Conv2D(out_channels, kernel_size=3, strides=1, padding='same', groups=groups, use_bias=False)(relu)
    bn2 = tf.keras.layers.BatchNormalization()(conv2)
    
    if stride != 1 or in_channels != out_channels:
        shortcut = tf.keras.layers.Conv2D(out_channels, kernel_size=1, strides=stride, use_bias=False)(inputs)
        shortcut = tf.keras.layers.BatchNormalization()(shortcut)
    else:
        shortcut = inputs
    
    out = tf.keras.layers.add([bn2, shortcut])
    out = tf.keras.layers.ReLU()(out)
    return out
def resnest_block(inputs, filters, strides, kernel_regularizer=None):
    # 1x1 conv
    x = tf.keras.layers.Conv2D(filters // 4, (1, 1), strides=strides, padding='same',
                               kernel_regularizer=kernel_regularizer)(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)

    # 3x3 conv with split attention
    x = tf.keras.layers.Conv2D(filters // 4, (3, 3), strides=(1, 1), padding='same',
                               kernel_regularizer=kernel_regularizer)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)

    x_split = tf.split(x, 4, axis=-1)
    x = tf.concat([tf.reduce_mean(x_split[0:1], axis=0),
                   tf.reduce_max(x_split[1:2], axis=0),
                   tf.reduce_mean(x_split[2:3], axis=0),
                   tf.reduce_max(x_split[3:4], axis=0)], axis=-1)

    # 1x1 conv
    x = tf.keras.layers.Conv2D(filters, (1, 1), strides=(1, 1), padding='same',
                               kernel_regularizer=kernel_regularizer)(x)
    x = tf.keras.layers.BatchNormalization()(x)

    # Residual connection
    shortcut = tf.keras.layers.Conv2D(filters, (1, 1), strides=strides, padding='same',
                                      kernel_regularizer=kernel_regularizer)(inputs)
    shortcut = tf.keras.layers.BatchNormalization()(shortcut)

    x = tf.keras.layers.Add()([x, shortcut])
    x = tf.keras.layers.Activation('relu')(x)

    return x

def ResNeSt50(input_shape, kernel_regularizer=None):
    inputs = tf.keras.layers.Input(shape=input_shape)
    x = tf.keras.layers.Conv2D(64, (7, 7), strides=(2, 2), padding='same',
                               kernel_regularizer=kernel_regularizer)(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.Activation('relu')(x)
    x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)

    # Replace the last layers with appropriate convolutional and activation layers
    x = resnest_block1(x, 64,64, stride=1, groups=1)
    x = resnest_block1(x, 64,64, stride=1, groups=1)
    x = resnest_block1(x, 64,64, stride=1, groups=1)
    """
    # Replace the last layers with appropriate convolutional and activation layers
    x = resnest_block(x, 256, strides=(1, 1), kernel_regularizer=kernel_regularizer)
    x = resnest_block(x, 256, strides=(1, 1), kernel_regularizer=kernel_regularizer)
    x = resnest_block(x, 256, strides=(1, 1), kernel_regularizer=kernel_regularizer)
    """
    # Adjust the output layer to have a single channel and use a suitable activation function
    outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(x)
    outputs = tf.keras.layers.UpSampling2D(size=(4, 4))(outputs)  # Upsample to get (256, 256)

    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

# Example usage:
input_shape = (256, 256, 1)  # Example input shape
model = ResNeSt50(input_shape)

model.compile(optimizer=Adam(), loss="binary_crossentropy", metrics=["accuracy",dice_coef,precision,iou,recall])

model.summary()
