callbacks = [
    EarlyStopping(patience=30, verbose=1),
    ReduceLROnPlateau(factor=0.01, patience=15, min_lr=0.00001, verbose=1),
    ModelCheckpoint('model-old-refinenet', verbose=1, save_best_only=True, save_weights_only=True)]

#phase d'entrainement
results = model.fit(X_train, y_train, batch_size=5, epochs=100, callbacks=callbacks, validation_data=(X_valid, y_valid))



#loss
plt.figure(figsize=(8, 8))
plt.title("Training and validation loss")
plt.plot(results.history["loss"], label="loss")
plt.plot(results.history["val_loss"], label="val_loss")
plt.plot( np.argmin(results.history["val_loss"]), np.min(results.history["val_loss"]), marker="x", color="r", label="best model")
plt.xlabel("Epochs")
plt.ylabel("log_loss")
plt.legend();

#accuracy
plt.figure(figsize=(8, 8))
acc = results.history['accuracy']
val_acc = results.history['val_accuracy']
epochs = range(len(acc))
plt.plot(epochs, acc, 'r', label='Training acc')
plt.plot(epochs, val_acc, 'b', label='Validation acc')
plt.title('Training and validation accuracy')
plt.plot( np.argmax(results.history["val_accuracy"]), np.max(results.history["val_accuracy"]), marker="x", color="r", label="best model")
plt.xlabel("Epochs")
plt.ylabel("log_acc")
plt.legend()
plt.figure()



model.evaluate(X_train, y_train)
model.evaluate(X_valid, y_valid)
model.evaluate(X_test, y_test)



preds_train = model.predict(X_train, verbose=1)
preds_val = model.predict(X_test, verbose=1)
preds_test = model.predict(X_test,verbose=1)
# Threshold predictions
preds_train_t = (preds_train > 0.5).astype(np.uint8)
preds_val_t = (preds_val > 0.5).astype(np.uint8)
preds_test_t = (preds_test > 0.5).astype(np.uint8)

def plot_sample(X, y, preds, binary_preds, ix=None):
    """Function to plot the results"""
    if ix is None:
        ix = random.randint(0, len(X))

    has_mask = y[ix].max() > 0

    fig, ax = plt.subplots(1, 4, figsize=(20, 10))
    ax[0].imshow(X[ix, ..., 0], cmap='gray')
    if has_mask:
        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])
    ax[0].set_title('image')

    ax[1].imshow(y[ix].squeeze())
    ax[1].set_title('mask')

    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)
    if has_mask:
        ax[2].contour(y[ix].squeeze(), colors='k', levels=[0.5])
    ax[2].set_title('mask Predicted')

    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)
    if has_mask:
        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])
    ax[3].set_title('mask Predicted binary');

# Check if training data looks all right
plot_sample(X_train, y_train, preds_train, preds_train_t, ix=2)


# Check if valid data looks all right
plot_sample(X_valid, y_valid, preds_val, preds_val_t, ix=1)

# Check if test data looks all right
plot_sample(X_test, y_test, preds_test, preds_test_t, ix=2)
